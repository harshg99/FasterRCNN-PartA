{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train2_v2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTBV17sBWQtY","executionInfo":{"status":"ok","timestamp":1636013890918,"user_tz":240,"elapsed":1399,"user":{"displayName":"Harsh Goel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10557291504800936508"}},"outputId":"76e408e6-6402-4775-a714-a80644144bd0"},"source":["#Basic Initialization\n","\n","#Code:\n"," #setting path in colab\n"," #mount the drive first\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount= True)\n","import os\n","\n","#set the working directory \n","\n","root_dir = \"/content/drive/My Drive/\"\n","\n","#choose the project folder\n","project_folder = \"CIS680HW/HW4/\"\n","\n","#define a function to create and set the working directory\n","def create_and_set_working_directory(project_folder):\n","  #check if the project folder exists. if not, make one.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + 'did not existed and was created.')\n","  \n","  #change the OS path to project folder as working directory\n","  os.chdir(root_dir + project_folder)\n","\n","  #create a test file in the working directory and see if it shows up at the right place\n","  !touch 'new_file_test.txt'\n","  print('working directory' + root_dir + project_folder + \\\n","        \"empty text file created. You can also run !pwd command to confirm working directory.\")\n","\n","create_and_set_working_directory(project_folder)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","working directory/content/drive/My Drive/CIS680HW/HW4/empty text file created. You can also run !pwd command to confirm working directory.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mltgG8EYne0O","executionInfo":{"status":"ok","timestamp":1636013675440,"user_tz":240,"elapsed":111,"user":{"displayName":"Harsh Goel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10557291504800936508"}},"outputId":"d501dd4a-05b4-423a-baa0-adb2a4029259"},"source":["cd /content/drive/MyDrive/CIS680HW/HW4\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CIS680HW/HW4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"vww-CVsAoT2G","executionInfo":{"status":"ok","timestamp":1636013678500,"user_tz":240,"elapsed":140,"user":{"displayName":"Harsh Goel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10557291504800936508"}},"outputId":"e5d01320-866e-43c1-81f7-4576ef3572d6"},"source":["os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/CIS680HW/HW4'"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"rs-SOpCxedDP","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1636013627516,"user_tz":240,"elapsed":179,"user":{"displayName":"Harsh Goel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10557291504800936508"}},"outputId":"a0e1366d-4894-4948-e56d-7ac312a4894c"},"source":["from rpn import *\n","from dataset import BuildDataLoader, BuildDataset\n","import torch.optim as optim"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-5a228144a4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrpn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuildDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuildDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rpn'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"id":"xSFYcSxFUKfn"},"source":["imgs_path = root_dir + 'CIS680HW' + '/HW3/data/hw3_mycocodata_img_comp_zlib.h5'\n","masks_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_mask_comp_zlib.h5'\n","labels_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_labels_comp_zlib.npy'\n","bboxes_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_bboxes_comp_zlib.npy'\n","paths = [imgs_path, masks_path, labels_path, bboxes_path]\n","# load the data into data.Dataset\n","dataset = BuildDataset(paths)\n","\n","# build the dataloader\n","# set 20% of the dataset as the training data\n","full_size = len(dataset)\n","train_size = int(full_size * 0.8)\n","test_size = full_size - train_size\n","torch.random.manual_seed(1)    \n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","    \n","batch_size = 8\n","train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","train_loader = train_build_loader.loader()\n","test_build_loader = BuildDataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n","test_loader = test_build_loader.loader()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv8fVHMpa_l_"},"source":["if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1OXRtakULR6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fdf1f7d-65de-494b-c559-253822f2c6b1"},"source":["rpn_net = RPNHead().to(device)\n","rpn_net2 = RPNHead().to(device)\n","optimizer = optim.SGD(rpn_net.parameters(),lr = 0.002,weight_decay=1.0e-4,momentum=0.90)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25,35], gamma=0.20)\n","epochs = 40\n","batch_loss_list = []\n","batch_loss_c_list = []\n","batch_loss_r_list = []\n","batch_loss_list_test = []\n","batch_loss_c_list_test = []\n","batch_loss_r_list_test = []\n","\n","for e in range(epochs):\n","    batch_loss = 0\n","    batch_loss_c = 0\n","    batch_loss_r = 0\n","    print(\"Epoch {}\".format(e))\n","    #optimizer = optim.SGD(rpn_net.parameters(),lr = 0.001,weight_decay=1.0e-4,momentum=0.90)\n","    for i, batch in enumerate(train_loader):\n","        #pdb.set_trace()\n","        X = batch['images'].to(device)\n","        images = batch['images'][0,:,:,:]\n","        indexes = batch['indexes']\n","        boxes = batch['bboxes']\n","        gt, ground_coord = rpn_net.create_batch_truth(boxes,indexes,images.shape[-2:]) \n","        cls_out, reg_out = rpn_net.forward(X)\n","        loss, loss_c, loss_r = rpn_net.compute_loss(cls_out, reg_out, gt.to(device), ground_coord.to(device),effective_batch=batch_size*20)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        batch_loss +=loss.cpu().item()\n","        batch_loss_c += loss_c.cpu().item()\n","        batch_loss_r += loss_r.cpu().item()\n","        \n","        if i % 100 == 0:\n","          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.\n","                  format(e, i * len(batch['images']), train_size,\n","                        100. * i / len(train_loader), loss.cpu().item()))\n","\n","    print(\"Total Loss, Loss Class, Loss R: {} {}  {}\".format(batch_loss,batch_loss_c,batch_loss_r))\n","    batch_loss_test = 0\n","    batch_loss_c_test = 0\n","    batch_loss_r_test = 0\n","    for i, batch in enumerate(test_loader):\n","      X = batch['images'].to(device)\n","      images = batch['images'][0,:,:,:]\n","      indexes = batch['indexes']\n","      boxes = batch['bboxes']\n","      rpn_net.eval()\n","      cls_out, reg_out = rpn_net.forward(X)\n","      gt, ground_coord = rpn_net2.create_batch_truth(boxes,indexes,images.shape[-2:]) \n","      loss, loss_c, loss_r = rpn_net.compute_loss(cls_out, reg_out, gt.to(device), ground_coord.to(device),effective_batch=batch_size*8)\n","      batch_loss_test +=loss.cpu().item()\n","      batch_loss_c_test += loss_c.cpu().item()\n","      batch_loss_r_test += loss_r.cpu().item()\n","\n","    batch_loss_list.append(batch_loss/len(train_loader))\n","    batch_loss_c_list.append(batch_loss_c/len(train_loader))\n","    batch_loss_r_list.append(batch_loss_r/len(train_loader))\n","    batch_loss_list_test.append(batch_loss_test/len(test_loader))\n","    batch_loss_c_list_test.append(batch_loss_c_test/len(test_loader))\n","    batch_loss_r_list_test.append(batch_loss_r_test/len(test_loader))\n","    scheduler.step()\n","torch.save(rpn_net.state_dict(), './model7.pth')\n","np.save('batch_loss.npy', np.array(batch_loss_list))\n","np.save('batch_loss_c.npy', np.array(batch_loss_c_list))\n","np.save('batch_loss_r.npy', np.array(batch_loss_r_list))\n","np.save('batch_loss_test.npy', np.array(batch_loss_list_test))\n","np.save('batch_loss_c_test.npy', np.array(batch_loss_c_list_test))\n","np.save('batch_loss_r_test.npy', np.array(batch_loss_r_list_test))"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/2612 (0%)]\tLoss: 2.413911\n","Train Epoch: 0 [800/2612 (31%)]\tLoss: 1.229344\n","Train Epoch: 0 [1600/2612 (61%)]\tLoss: 2.035243\n","Train Epoch: 0 [2400/2612 (92%)]\tLoss: 1.289313\n","Total Loss, Loss Class, Loss R: 464.4365973472595 209.15272682905197  127.64193508028984\n","Epoch 1\n","Train Epoch: 1 [0/2612 (0%)]\tLoss: 1.542124\n","Train Epoch: 1 [800/2612 (31%)]\tLoss: 1.094012\n","Train Epoch: 1 [1600/2612 (61%)]\tLoss: 1.412448\n","Train Epoch: 1 [2400/2612 (92%)]\tLoss: 2.314384\n","Total Loss, Loss Class, Loss R: 449.4614147543907 212.27259850502014  118.59440748393536\n","Epoch 2\n","Train Epoch: 2 [0/2612 (0%)]\tLoss: 1.045784\n","Train Epoch: 2 [800/2612 (31%)]\tLoss: 1.217412\n","Train Epoch: 2 [1600/2612 (61%)]\tLoss: 1.035285\n","Train Epoch: 2 [2400/2612 (92%)]\tLoss: 1.102684\n","Total Loss, Loss Class, Loss R: 440.473734498024 207.37046992778778  116.55163238942623\n","Epoch 3\n","Train Epoch: 3 [0/2612 (0%)]\tLoss: 1.044611\n","Train Epoch: 3 [800/2612 (31%)]\tLoss: 1.044445\n","Train Epoch: 3 [1600/2612 (61%)]\tLoss: 0.982447\n","Train Epoch: 3 [2400/2612 (92%)]\tLoss: 1.142827\n","Total Loss, Loss Class, Loss R: 432.6426457762718 203.83047431707382  114.40608569979668\n","Epoch 4\n","Train Epoch: 4 [0/2612 (0%)]\tLoss: 1.196070\n","Train Epoch: 4 [800/2612 (31%)]\tLoss: 1.701099\n","Train Epoch: 4 [1600/2612 (61%)]\tLoss: 1.222197\n","Train Epoch: 4 [2400/2612 (92%)]\tLoss: 1.130060\n","Total Loss, Loss Class, Loss R: 425.7775499224663 203.6230128109455  111.0772677809\n","Epoch 5\n","Train Epoch: 5 [0/2612 (0%)]\tLoss: 1.079056\n","Train Epoch: 5 [800/2612 (31%)]\tLoss: 1.228956\n","Train Epoch: 5 [1600/2612 (61%)]\tLoss: 1.163880\n","Train Epoch: 5 [2400/2612 (92%)]\tLoss: 2.196449\n","Total Loss, Loss Class, Loss R: 420.40264868736267 199.6620723605156  110.37028843164444\n","Epoch 6\n","Train Epoch: 6 [0/2612 (0%)]\tLoss: 1.503781\n","Train Epoch: 6 [800/2612 (31%)]\tLoss: 2.289177\n","Train Epoch: 6 [1600/2612 (61%)]\tLoss: 1.012790\n","Train Epoch: 6 [2400/2612 (92%)]\tLoss: 1.026989\n","Total Loss, Loss Class, Loss R: 411.16239070892334 195.86707264184952  107.64765913039446\n","Epoch 7\n","Train Epoch: 7 [0/2612 (0%)]\tLoss: 1.014762\n","Train Epoch: 7 [800/2612 (31%)]\tLoss: 0.893798\n","Train Epoch: 7 [1600/2612 (61%)]\tLoss: 2.121465\n","Train Epoch: 7 [2400/2612 (92%)]\tLoss: 1.089922\n","Total Loss, Loss Class, Loss R: 406.4559750556946 194.82943484187126  105.81326933205128\n","Epoch 8\n","Train Epoch: 8 [0/2612 (0%)]\tLoss: 1.799542\n","Train Epoch: 8 [800/2612 (31%)]\tLoss: 1.131821\n","Train Epoch: 8 [1600/2612 (61%)]\tLoss: 1.014715\n","Train Epoch: 8 [2400/2612 (92%)]\tLoss: 2.513158\n","Total Loss, Loss Class, Loss R: 416.3985716700554 196.91950151324272  109.73953466117382\n","Epoch 9\n","Train Epoch: 9 [0/2612 (0%)]\tLoss: 0.999392\n","Train Epoch: 9 [800/2612 (31%)]\tLoss: 2.023750\n","Train Epoch: 9 [1600/2612 (61%)]\tLoss: 1.081265\n","Train Epoch: 9 [2400/2612 (92%)]\tLoss: 1.107340\n","Total Loss, Loss Class, Loss R: 410.7042347788811 195.87074741721153  107.41674370318651\n","Epoch 10\n","Train Epoch: 10 [0/2612 (0%)]\tLoss: 1.066901\n","Train Epoch: 10 [800/2612 (31%)]\tLoss: 0.931618\n","Train Epoch: 10 [1600/2612 (61%)]\tLoss: 1.438552\n","Train Epoch: 10 [2400/2612 (92%)]\tLoss: 0.912171\n","Total Loss, Loss Class, Loss R: 406.4027843475342 193.51517021656036  106.44380677491426\n","Epoch 11\n","Train Epoch: 11 [0/2612 (0%)]\tLoss: 1.413713\n","Train Epoch: 11 [800/2612 (31%)]\tLoss: 2.056003\n","Train Epoch: 11 [1600/2612 (61%)]\tLoss: 1.052270\n","Train Epoch: 11 [2400/2612 (92%)]\tLoss: 1.021555\n","Total Loss, Loss Class, Loss R: 407.58443558216095 194.45933094620705  106.56255207210779\n","Epoch 12\n","Train Epoch: 12 [0/2612 (0%)]\tLoss: 1.275713\n","Train Epoch: 12 [800/2612 (31%)]\tLoss: 0.993955\n","Train Epoch: 12 [1600/2612 (61%)]\tLoss: 1.069360\n","Train Epoch: 12 [2400/2612 (92%)]\tLoss: 0.960749\n","Total Loss, Loss Class, Loss R: 406.7335596680641 193.65128776431084  106.54113587737083\n","Epoch 13\n","Train Epoch: 13 [0/2612 (0%)]\tLoss: 1.522319\n","Train Epoch: 13 [800/2612 (31%)]\tLoss: 0.978661\n","Train Epoch: 13 [1600/2612 (61%)]\tLoss: 1.138408\n","Train Epoch: 13 [2400/2612 (92%)]\tLoss: 0.881648\n","Total Loss, Loss Class, Loss R: 406.9774380326271 192.0522335767746  107.46260184794664\n","Epoch 14\n","Train Epoch: 14 [0/2612 (0%)]\tLoss: 2.136112\n","Train Epoch: 14 [800/2612 (31%)]\tLoss: 1.100941\n","Train Epoch: 14 [1600/2612 (61%)]\tLoss: 1.188644\n","Train Epoch: 14 [2400/2612 (92%)]\tLoss: 0.810688\n","Total Loss, Loss Class, Loss R: 404.6771695613861 190.53123652935028  107.07296562194824\n","Epoch 15\n","Train Epoch: 15 [0/2612 (0%)]\tLoss: 0.950514\n","Train Epoch: 15 [800/2612 (31%)]\tLoss: 1.085083\n","Train Epoch: 15 [1600/2612 (61%)]\tLoss: 0.859241\n"]}]},{"cell_type":"code","metadata":{"id":"viOycemMW1Qt"},"source":["torch.save(rpn_net.state_dict(), './model3_HG.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fGPF59mjYIa"},"source":["Part 5 and Part 6 outputs"]},{"cell_type":"code","metadata":{"id":"7oaljbkGjef0"},"source":["from rpn import *\n","from dataset import BuildDataLoader, BuildDataset\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pdb\n","\n","def visualise_labels(images, labels, masks, bboxes ):\n","    plt.figure()\n","    plt.axes()\n","\n","    plot=images.numpy()\n","    \n","    plot= np.moveaxis(plot,0,-1)\n","    print(plot.shape)\n","    print(len(labels))\n","    for i in range(len(labels)):\n","        show_mask= masks[0][i].numpy()\n","        print(show_mask.shape)\n","        if labels[i]==0:\n","          pass\n","        if labels[i]==1:\n","            plot[:,:,0] += show_mask*3 \n","        if labels[i]==2:\n","            plot[:,:,1] += show_mask*3 \n","        if labels[i]==3:\n","            plot[:,:,2] += show_mask*3 \n","\n","    plt.imshow(np.clip(plot,0,1))\n","\n","    for i in range(len(bboxes)):\n","        rectangle = plt.Rectangle((bboxes[i][0],bboxes[i][1]), bboxes[i][2]-bboxes[i][0],bboxes[i][3]-bboxes[i][1],fill=False, ec='r', lw=3)\n","        plt.gca().add_patch(rectangle)\n","\n","def plot(ground_coord,gt,images,model,string='ground',i=0,anchors=None):\n","      \n","        fig,ax=plt.subplots(1,1)\n","        ax.imshow(images.permute(1,2,0))\n","        if gt.ndim == 1:\n","          find_cor=(gt==1).nonzero()\n","        else:\n","          find_cor=(gt==1).squeeze().nonzero()\n","        find_neg=(gt==0).squeeze().nonzero()\n","        for elem in find_cor:\n","            coord = torch.squeeze(ground_coord[elem,:].view(-1, 4))\n","            coord[0] = 0 if coord[0]<0 else coord[0]\n","            coord[1] = 0 if coord[1]<0 else coord[1]\n","            coord[2] = 800 if coord[0]>800 else coord[2]\n","            coord[3] = 1088 if coord[3]>1088 else coord[3]\n","            col='r'\n","            rect=patches.Rectangle((coord[0],coord[1]),coord[2]-coord[0],coord[3]-coord[1],fill=False,color=col)\n","            ax.add_patch(rect)\n","            if anchors is not None:\n","              anchor=anchors[elem,:]\n","              rect=patches.Rectangle((anchor[0],anchor[1]),anchor[2]-anchor[0],anchor[3]-anchor[1],fill=False,color='b')\n","              ax.add_patch(rect)\n","        plt.show()\n","        #plt.savefig(\"./results/\"+string+\"_truth_visualizations/images_{}\".format(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OBDqMXZjWtp"},"source":["\n","imgs_path = './data/hw3_mycocodata_img_comp_zlib.h5'\n","masks_path = './data/hw3_mycocodata_mask_comp_zlib.h5'\n","labels_path = './data/hw3_mycocodata_labels_comp_zlib.npy'\n","bboxes_path = './data/hw3_mycocodata_bboxes_comp_zlib.npy'\n","paths = [imgs_path, masks_path, labels_path, bboxes_path]\n","# load the data into data.Dataset\n","dataset = BuildDataset(paths)\n","\n","\n","# build the dataloader\n","# set 20% of the dataset as the training data\n","full_size = len(dataset)\n","train_size = int(full_size * 0.8)\n","test_size = full_size - train_size\n","torch.random.manual_seed(1)    \n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","    \n","batch_size = 1\n","train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","train_loader = iter(train_build_loader.loader())\n","test_build_loader = BuildDataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n","test_loader = iter(test_build_loader.loader())\n","\n","model = RPNHead()\n","# push the randomized training data into the dataloader\n","\n","model.load_state_dict(torch.load('./model7.pth'))\n","for i,batch in enumerate(train_loader,0):\n","    images=batch['images'][0,:,:,:]\n","    indexes=batch['indexes']\n","    boxes=batch['bboxes']\n","    print(boxes)\n","    print(batch['labels'])\n","    #pdb.set_trace()\n","    # visualise_labels(images.clone(),batch['labels'][0].copy(),batch['masks'][0].clone(),boxes[0].copy())\n","    gt,ground_coord=model.create_batch_truth(boxes,indexes,images.shape[-2:])\n","\n","    flatten_coord,flatten_gt,flatten_anchors=output_flattening(ground_coord,gt,model.get_anchors())\n","\n","    # Decode the ground truth box to get the upper left and lower right corners of the ground truth boxes\n","    decoded_coord=output_decoding(flatten_coord,flatten_anchors)\n","\n","    # Plot the image and the anchor boxes with the positive labels and their corresponding ground truth box\n","    images = transforms.functional.normalize(images,\n","                                                  [-0.485/0.229, -0.456/0.224, -0.406/0.225],\n","                                                  [1/0.229, 1/0.224, 1/0.225], inplace=False)\n","    plot(decoded_coord,flatten_gt,images,model,string='ground',i=i,anchors=flatten_anchors)\n","\n","    ## Forward\n","    model.eval()\n","    cls_out, reg_out = model.forward(batch['images'])\n","    flatten_coord,flatten_gt,flatten_anchors=output_flattening(reg_out.detach(),cls_out.detach(),model.get_anchors())\n","    \n","    # Decode the ground truth box to get the upper left and lower right corners of the ground truth boxes for Part 5\n","    decoded_coord=output_decoding(flatten_coord,flatten_anchors)\n","\n","    sort_clas,indices = torch.sort(flatten_gt,dim = 0, descending=True)\n","\n","    top_proposals = indices[:20]\n","    top_proposals_clas = sort_clas[:20]\n","\n","    #print(top_proposals_clas)\n","    #print(flatten_coord[top_proposals,:])\n","    top_proposals_clas[top_proposals_clas>0] = 1\n","    top_proposals_reg = decoded_coord[top_proposals,:]\n","\n","    #print(top_proposals_reg)\n","    plot(top_proposals_reg,top_proposals_clas,images,model,string='prediction',i=i)\n","\n","    # # part 6 inference results\n","    \n","    nms_clas_list, nms_prebox_list,pre_nms_clas_list, pre_nms_prebox_list = model.postprocess(cls_out,reg_out,IOU_thresh=0.4)\n","    nms_clas_list[0][nms_clas_list[0]>0] = 1\n","    pre_nms_clas_list[0][pre_nms_clas_list[0]>0] = 1\n","    \n","    # pdb.set_trace()\n","    plot(pre_nms_prebox_list[0].squeeze(),pre_nms_clas_list[0],images,model,string='predictionpreNMS',i=i)\n","    plot(nms_prebox_list[0],nms_clas_list[0],images,model,string='predictionpostNMS',i=i)\n","    plt.show()\n","\n","    if(i>5):\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2HIcPEp3_iL"},"source":[""],"execution_count":null,"outputs":[]}]}