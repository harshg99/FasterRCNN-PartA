{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of train2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTBV17sBWQtY","executionInfo":{"status":"ok","timestamp":1636010338052,"user_tz":240,"elapsed":44829,"user":{"displayName":"Zeeshan Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06566830088353701514"}},"outputId":"23b90589-9024-4096-82d5-99495797aee1"},"source":["#Basic Initialization\n","\n","#Code:\n"," #setting path in colab\n"," #mount the drive first\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount= True)\n","import os\n","\n","#set the working directory \n","\n","root_dir = \"/content/drive/My Drive/\"\n","\n","#choose the project folder\n","project_folder = \"CIS680HW/HW4/\"\n","\n","#define a function to create and set the working directory\n","def create_and_set_working_directory(project_folder):\n","  #check if the project folder exists. if not, make one.\n","  if os.path.isdir(root_dir + project_folder) == False:\n","    os.mkdir(root_dir + project_folder)\n","    print(root_dir + project_folder + 'did not existed and was created.')\n","  \n","  #change the OS path to project folder as working directory\n","  os.chdir(root_dir + project_folder)\n","\n","  #create a test file in the working directory and see if it shows up at the right place\n","  !touch 'new_file_test.txt'\n","  print('working directory' + root_dir + project_folder + \\\n","        \"empty text file created. You can also run !pwd command to confirm working directory.\")\n","\n","create_and_set_working_directory(project_folder)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","working directory/content/drive/My Drive/CIS680HW/HW4/empty text file created. You can also run !pwd command to confirm working directory.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mltgG8EYne0O","executionInfo":{"status":"ok","timestamp":1636010393267,"user_tz":240,"elapsed":304,"user":{"displayName":"Zeeshan Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06566830088353701514"}},"outputId":"cc78dade-fb59-4eab-b300-1789278739e5"},"source":["cd /content/drive/MyDrive/CIS680HW/HW4\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CIS680HW/HW4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vww-CVsAoT2G","executionInfo":{"status":"ok","timestamp":1636010395254,"user_tz":240,"elapsed":439,"user":{"displayName":"Zeeshan Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06566830088353701514"}},"outputId":"b30b3e70-95a3-4434-97f4-7ae9e24a921a"},"source":["os.getcwd()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/CIS680HW/HW4'"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBlP-C_J08_D","executionInfo":{"status":"ok","timestamp":1636010582753,"user_tz":240,"elapsed":356,"user":{"displayName":"Zeeshan Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06566830088353701514"}},"outputId":"b40094f0-c588-4103-ab02-1a1b81e20fa6"},"source":["os.listdir()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['new_file_test.txt']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"rs-SOpCxedDP","colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"status":"error","timestamp":1636010498422,"user_tz":240,"elapsed":277,"user":{"displayName":"Zeeshan Islam","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06566830088353701514"}},"outputId":"c2764ae2-cccd-456d-ef83-eb589f58ed77"},"source":["from rpn import *\n","from dataset import BuildDataLoader, BuildDataset\n","import torch.optim as optim"],"execution_count":6,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-5a228144a4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrpn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuildDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuildDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rpn'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"id":"xSFYcSxFUKfn"},"source":["imgs_path = root_dir + 'CIS680HW' + '/HW3/data/hw3_mycocodata_img_comp_zlib.h5'\n","masks_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_mask_comp_zlib.h5'\n","labels_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_labels_comp_zlib.npy'\n","bboxes_path = root_dir + 'CIS680HW'+'/HW3/data/hw3_mycocodata_bboxes_comp_zlib.npy'\n","paths = [imgs_path, masks_path, labels_path, bboxes_path]\n","# load the data into data.Dataset\n","dataset = BuildDataset(paths)\n","\n","# build the dataloader\n","# set 20% of the dataset as the training data\n","full_size = len(dataset)\n","train_size = int(full_size * 0.8)\n","test_size = full_size - train_size\n","torch.random.manual_seed(1)    \n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","    \n","batch_size = 8\n","train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","train_loader = train_build_loader.loader()\n","test_build_loader = BuildDataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n","test_loader = test_build_loader.loader()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nv8fVHMpa_l_"},"source":["if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1OXRtakULR6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b52c30cb-86e5-4aff-be20-e9336f28fe3c"},"source":["rpn_net = RPNHead().to(device)\n","rpn_net2 = RPNHead().to(device)\n","optimizer = optim.SGD(rpn_net.parameters(),lr = 0.005,weight_decay=1.0e-4,momentum=0.90)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25,35], gamma=0.20)\n","epochs = 40\n","batch_loss_list = []\n","batch_loss_c_list = []\n","batch_loss_r_list = []\n","batch_loss_list_test = []\n","batch_loss_c_list_test = []\n","batch_loss_r_list_test = []\n","\n","for e in range(epochs):\n","    batch_loss = 0\n","    batch_loss_c = 0\n","    batch_loss_r = 0\n","    print(\"Epoch {}\".format(e))\n","    #optimizer = optim.SGD(rpn_net.parameters(),lr = 0.001,weight_decay=1.0e-4,momentum=0.90)\n","    for i, batch in enumerate(train_loader):\n","        #pdb.set_trace()\n","        X = batch['images'].to(device)\n","        images = batch['images'][0,:,:,:]\n","        indexes = batch['indexes']\n","        boxes = batch['bboxes']\n","        gt, ground_coord = rpn_net.create_batch_truth(boxes,indexes,images.shape[-2:]) \n","        cls_out, reg_out = rpn_net.forward(X)\n","        loss, loss_c, loss_r = rpn_net.compute_loss(cls_out, reg_out, gt.to(device), ground_coord.to(device),effective_batch=batch_size*20)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        batch_loss +=loss.cpu().item()\n","        batch_loss_c += loss_c.cpu().item()\n","        batch_loss_r += loss_r.cpu().item()\n","        \n","        if i % 100 == 0:\n","          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.\n","                  format(e, i * len(batch['images']), train_size,\n","                        100. * i / len(train_loader), loss.cpu().item()))\n","\n","    print(\"Total Loss, Loss Class, Loss R: {} {}  {}\".format(batch_loss,batch_loss_c,batch_loss_r))\n","    batch_loss_test = 0\n","    batch_loss_c_test = 0\n","    batch_loss_r_test = 0\n","    for i, batch in enumerate(test_loader):\n","      X = batch['images'].to(device)\n","      images = batch['images'][0,:,:,:]\n","      indexes = batch['indexes']\n","      boxes = batch['bboxes']\n","      rpn_net.eval()\n","      cls_out, reg_out = rpn_net.forward(X)\n","      gt, ground_coord = rpn_net2.create_batch_truth(boxes,indexes,images.shape[-2:]) \n","      loss, loss_c, loss_r = rpn_net.compute_loss(cls_out, reg_out, gt.to(device), ground_coord.to(device),effective_batch=batch_size*8)\n","      batch_loss_test +=loss.cpu().item()\n","      batch_loss_c_test += loss_c.cpu().item()\n","      batch_loss_r_test += loss_r.cpu().item()\n","\n","    batch_loss_list.append(batch_loss/len(train_loader))\n","    batch_loss_c_list.append(batch_loss_c/len(train_loader))\n","    batch_loss_r_list.append(batch_loss_r/len(train_loader))\n","    batch_loss_list_test.append(batch_loss_test/len(test_loader))\n","    batch_loss_c_list_test.append(batch_loss_c_test/len(test_loader))\n","    batch_loss_r_list_test.append(batch_loss_r_test/len(test_loader))\n","    scheduler.step()\n","torch.save(rpn_net.state_dict(), './model8.pth')\n","np.save('batch_loss_zee.npy', np.array(batch_loss_list))\n","np.save('batch_loss_c_zee.npy', np.array(batch_loss_c_list))\n","np.save('batch_loss_r_zee.npy', np.array(batch_loss_r_list))\n","np.save('batch_loss_test_zee.npy', np.array(batch_loss_list_test))\n","np.save('batch_loss_c_test_zee.npy', np.array(batch_loss_c_list_test))\n","np.save('batch_loss_r_test_zee.npy', np.array(batch_loss_r_list_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/2612 (0%)]\tLoss: 2.413911\n"]}]},{"cell_type":"code","metadata":{"id":"viOycemMW1Qt"},"source":["torch.save(rpn_net.state_dict(), './model3_HG.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9fGPF59mjYIa"},"source":["Part 5 and Part 6 outputs"]},{"cell_type":"code","metadata":{"id":"7oaljbkGjef0"},"source":["from rpn import *\n","from dataset import BuildDataLoader, BuildDataset\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pdb\n","\n","def visualise_labels(images, labels, masks, bboxes ):\n","    plt.figure()\n","    plt.axes()\n","\n","    plot=images.numpy()\n","    \n","    plot= np.moveaxis(plot,0,-1)\n","    print(plot.shape)\n","    print(len(labels))\n","    for i in range(len(labels)):\n","        show_mask= masks[0][i].numpy()\n","        print(show_mask.shape)\n","        if labels[i]==0:\n","          pass\n","        if labels[i]==1:\n","            plot[:,:,0] += show_mask*3 \n","        if labels[i]==2:\n","            plot[:,:,1] += show_mask*3 \n","        if labels[i]==3:\n","            plot[:,:,2] += show_mask*3 \n","\n","    plt.imshow(np.clip(plot,0,1))\n","\n","    for i in range(len(bboxes)):\n","        rectangle = plt.Rectangle((bboxes[i][0],bboxes[i][1]), bboxes[i][2]-bboxes[i][0],bboxes[i][3]-bboxes[i][1],fill=False, ec='r', lw=3)\n","        plt.gca().add_patch(rectangle)\n","\n","def plot(ground_coord,gt,images,model,string='ground',i=0,anchors=None):\n","      \n","        fig,ax=plt.subplots(1,1)\n","        ax.imshow(images.permute(1,2,0))\n","        if gt.ndim == 1:\n","          find_cor=(gt==1).nonzero()\n","        else:\n","          find_cor=(gt==1).squeeze().nonzero()\n","        find_neg=(gt==0).squeeze().nonzero()\n","        for elem in find_cor:\n","            coord = torch.squeeze(ground_coord[elem,:].view(-1, 4))\n","            coord[0] = 0 if coord[0]<0 else coord[0]\n","            coord[1] = 0 if coord[1]<0 else coord[1]\n","            coord[2] = 800 if coord[0]>800 else coord[2]\n","            coord[3] = 1088 if coord[3]>1088 else coord[3]\n","            col='r'\n","            rect=patches.Rectangle((coord[0],coord[1]),coord[2]-coord[0],coord[3]-coord[1],fill=False,color=col)\n","            ax.add_patch(rect)\n","            if anchors is not None:\n","              anchor=anchors[elem,:]\n","              rect=patches.Rectangle((anchor[0],anchor[1]),anchor[2]-anchor[0],anchor[3]-anchor[1],fill=False,color='b')\n","              ax.add_patch(rect)\n","        plt.show()\n","        #plt.savefig(\"./results/\"+string+\"_truth_visualizations/images_{}\".format(i))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1QGdci_1TGRo9enJD27siHuuwBH4nABvI"},"id":"2OBDqMXZjWtp","executionInfo":{"status":"ok","timestamp":1636008746064,"user_tz":240,"elapsed":18296,"user":{"displayName":"Harsh Goel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11273194853457693199"}},"outputId":"47abcdbc-2bad-4019-f12a-ad7e6f6e5c37"},"source":["\n","imgs_path = './data/hw3_mycocodata_img_comp_zlib.h5'\n","masks_path = './data/hw3_mycocodata_mask_comp_zlib.h5'\n","labels_path = './data/hw3_mycocodata_labels_comp_zlib.npy'\n","bboxes_path = './data/hw3_mycocodata_bboxes_comp_zlib.npy'\n","paths = [imgs_path, masks_path, labels_path, bboxes_path]\n","# load the data into data.Dataset\n","dataset = BuildDataset(paths)\n","\n","\n","# build the dataloader\n","# set 20% of the dataset as the training data\n","full_size = len(dataset)\n","train_size = int(full_size * 0.8)\n","test_size = full_size - train_size\n","torch.random.manual_seed(1)    \n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","    \n","batch_size = 1\n","train_build_loader = BuildDataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n","train_loader = iter(train_build_loader.loader())\n","test_build_loader = BuildDataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n","test_loader = iter(test_build_loader.loader())\n","\n","model = RPNHead()\n","# push the randomized training data into the dataloader\n","\n","model.load_state_dict(torch.load('./model8.pth'))\n","for i,batch in enumerate(train_loader,0):\n","    images=batch['images'][0,:,:,:]\n","    indexes=batch['indexes']\n","    boxes=batch['bboxes']\n","    print(boxes)\n","    print(batch['labels'])\n","    #pdb.set_trace()\n","    visualise_labels(images.clone(),batch['labels'][0].copy(),batch['masks'][0].clone(),boxes[0].copy())\n","    gt,ground_coord=model.create_batch_truth(boxes,indexes,images.shape[-2:])\n","\n","    flatten_coord,flatten_gt,flatten_anchors=output_flattening(ground_coord,gt,model.get_anchors())\n","\n","    # Decode the ground truth box to get the upper left and lower right corners of the ground truth boxes\n","    decoded_coord=output_decoding(flatten_coord,flatten_anchors)\n","\n","    # Plot the image and the anchor boxes with the positive labels and their corresponding ground truth box\n","    images = transforms.functional.normalize(images,\n","                                                  [-0.485/0.229, -0.456/0.224, -0.406/0.225],\n","                                                  [1/0.229, 1/0.224, 1/0.225], inplace=False)\n","    plot(decoded_coord,flatten_gt,images,model,string='ground',i=i,anchors=flatten_anchors)\n","\n","    ## Forward\n","    model.eval()\n","    cls_out, reg_out = model.forward(batch['images'])\n","    flatten_coord,flatten_gt,flatten_anchors=output_flattening(reg_out.detach(),cls_out.detach(),model.get_anchors())\n","    \n","    # Decode the ground truth box to get the upper left and lower right corners of the ground truth boxes for Part 5\n","    decoded_coord=output_decoding(flatten_coord,flatten_anchors)\n","\n","    sort_clas,indices = torch.sort(flatten_gt,dim = 0, descending=True)\n","\n","    top_proposals = indices[:20]\n","    top_proposals_clas = sort_clas[:20]\n","\n","    #print(top_proposals_clas)\n","    #print(flatten_coord[top_proposals,:])\n","    top_proposals_clas[top_proposals_clas>0] = 1\n","    top_proposals_reg = decoded_coord[top_proposals,:]\n","\n","    #print(top_proposals_reg)\n","    plot(top_proposals_reg,top_proposals_clas,images,model,string='prediction',i=i)\n","\n","    # # part 6 inference results\n","    \n","    nms_clas_list, nms_prebox_list,pre_nms_clas_list, pre_nms_prebox_list = model.postprocess(cls_out,reg_out,IOU_thresh=0.4)\n","    nms_clas_list[0][nms_clas_list[0]>0] = 1\n","    pre_nms_clas_list[0][pre_nms_clas_list[0]>0] = 1\n","    \n","    # pdb.set_trace()\n","    plot(pre_nms_prebox_list[0].squeeze(),pre_nms_clas_list[0],images,model,string='predictionpreNMS',i=i)\n","    plot(nms_prebox_list[0],nms_clas_list[0],images,model,string='predictionpostNMS',i=i)\n","    plt.show()\n","\n","    if(i>5):\n","        break"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}